{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f0d6f4",
   "metadata": {},
   "source": [
    "<h1 style=\"background: linear-gradient(to right, #ff6b6b, #4ecdc4); \n",
    "           color: white; \n",
    "           padding: 20px; \n",
    "           border-radius: 10px; \n",
    "           text-align: center; \n",
    "           font-family: Arial, sans-serif; \n",
    "           text-shadow: 2px 2px 4px rgba(0,0,0,0.5);\">\n",
    "  Langchain with Amazon Bedrock\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a86d2a",
   "metadata": {},
   "source": [
    "## Introduction to LangChain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00c61c",
   "metadata": {},
   "source": [
    "LangChain is a framework for developing applications powered by language models. It provides a suite of tools and components to streamline the creation of complex applications that leverage the capabilities of large language models (LLMs). LangChain simplifies the integration of LLMs into various applications, enabling developers to build sophisticated language-based solutions with ease.\n",
    "\n",
    "Amazon Bedrock is a fully managed service that makes it easy to build, train, and deploy machine learning models at scale. By integrating LangChain with Amazon Bedrock, developers can harness the power of both platforms to create robust and scalable language model applications. This combination allows for seamless deployment and management of LLMs, providing a powerful solution for developing advanced language-based applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990230f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding: 15px; border-radius: 10px;\">\n",
    "  <p>An alternative is to use the SDK of the LLM provider you started with, like <code>boto3</code> for AWS. However, learning LangChain offers clear benefits:</p>\n",
    "  \n",
    "  <ol>\n",
    "    <li><b>Ease of Use:</b> Simplifies working with LLMs by abstracting API complexities, reducing code.</li>\n",
    "    <li><b>Flexibility:</b> Supports multiple LLM providers, making it easy to switch services.</li>\n",
    "    <li><b>Integration:</b> Works well with popular libraries like PyTorch and TensorFlow.</li>\n",
    "    <li><b>Community:</b> Large, active community with frequent updates and support.</li>\n",
    "  </ol>\n",
    "\n",
    "  <h4>Prebuilt Patterns</h4>\n",
    "  <p>LangChain provides common LLM patterns (e.g., chain-of-thought) to help you quickly get started. Use these to see if they meet your needs before diving into more complex implementations.</p>\n",
    "\n",
    "  <h4>Interchangeable Components</h4>\n",
    "  <p>LangChain components (e.g., LLMs, output parsers) are easily swapped, future-proofing your application as models and needs evolve.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59740b0a",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a6c492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-community\n",
    "# %pip install langchain-aws "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50047f74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Model Name                     | Model ID                                       | Input Modalities   | Output Modalities   |\n",
      "+================================+================================================+====================+=====================+\n",
      "| Titan Text Large               | amazon.titan-tg1-large                         | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Image Generator G1       | amazon.titan-image-generator-v1:0              | TEXT, IMAGE        | IMAGE               |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Image Generator G1       | amazon.titan-image-generator-v1                | TEXT, IMAGE        | IMAGE               |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Image Generator G1 v2    | amazon.titan-image-generator-v2:0              | TEXT, IMAGE        | IMAGE               |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text G1 - Premier        | amazon.titan-text-premier-v1:0                 | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Olympus Lite v1                | amazon.olympus-1-lite-v1:0                     | TEXT, IMAGE, VIDEO | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text Embeddings v2       | amazon.titan-embed-g1-text-02                  | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text G1 - Lite           | amazon.titan-text-lite-v1:0:4k                 | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text G1 - Lite           | amazon.titan-text-lite-v1                      | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text G1 - Express        | amazon.titan-text-express-v1:0:8k              | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text G1 - Express        | amazon.titan-text-express-v1                   | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Embeddings G1 - Text     | amazon.titan-embed-text-v1:2:8k                | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Embeddings G1 - Text     | amazon.titan-embed-text-v1                     | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text Embeddings V2       | amazon.titan-embed-text-v2:0:8k                | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Text Embeddings V2       | amazon.titan-embed-text-v2:0                   | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Multimodal Embeddings G1 | amazon.titan-embed-image-v1:0                  | TEXT, IMAGE        | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Titan Multimodal Embeddings G1 | amazon.titan-embed-image-v1                    | TEXT, IMAGE        | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| SDXL 1.0                       | stability.stable-diffusion-xl-v1:0             | TEXT, IMAGE        | IMAGE               |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| SDXL 1.0                       | stability.stable-diffusion-xl-v1               | TEXT, IMAGE        | IMAGE               |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| J2 Grande Instruct             | ai21.j2-grande-instruct                        | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| J2 Jumbo Instruct              | ai21.j2-jumbo-instruct                         | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Jurassic-2 Mid                 | ai21.j2-mid                                    | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Jurassic-2 Mid                 | ai21.j2-mid-v1                                 | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Jurassic-2 Ultra               | ai21.j2-ultra                                  | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Jurassic-2 Ultra               | ai21.j2-ultra-v1:0:8k                          | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Jurassic-2 Ultra               | ai21.j2-ultra-v1                               | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Jamba-Instruct                 | ai21.jamba-instruct-v1:0                       | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude Instant                 | anthropic.claude-instant-v1:2:100k             | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude Instant                 | anthropic.claude-instant-v1                    | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude                         | anthropic.claude-v2:0:18k                      | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude                         | anthropic.claude-v2:0:100k                     | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude                         | anthropic.claude-v2:1:18k                      | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude                         | anthropic.claude-v2:1:200k                     | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude                         | anthropic.claude-v2:1                          | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude                         | anthropic.claude-v2                            | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Sonnet                | anthropic.claude-3-sonnet-20240229-v1:0:28k    | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Sonnet                | anthropic.claude-3-sonnet-20240229-v1:0:200k   | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Sonnet                | anthropic.claude-3-sonnet-20240229-v1:0        | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Haiku                 | anthropic.claude-3-haiku-20240307-v1:0:48k     | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Haiku                 | anthropic.claude-3-haiku-20240307-v1:0:200k    | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Haiku                 | anthropic.claude-3-haiku-20240307-v1:0         | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Opus                  | anthropic.claude-3-opus-20240229-v1:0:12k      | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Opus                  | anthropic.claude-3-opus-20240229-v1:0:28k      | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Opus                  | anthropic.claude-3-opus-20240229-v1:0:200k     | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3 Opus                  | anthropic.claude-3-opus-20240229-v1:0          | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3.5 Sonnet              | anthropic.claude-3-5-sonnet-20240620-v1:0:18k  | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3.5 Sonnet              | anthropic.claude-3-5-sonnet-20240620-v1:0:51k  | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3.5 Sonnet              | anthropic.claude-3-5-sonnet-20240620-v1:0:200k | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Claude 3.5 Sonnet              | anthropic.claude-3-5-sonnet-20240620-v1:0      | TEXT, IMAGE        | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Command                        | cohere.command-text-v14:7:4k                   | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Command                        | cohere.command-text-v14                        | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Command R                      | cohere.command-r-v1:0                          | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Command R+                     | cohere.command-r-plus-v1:0                     | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Command Light                  | cohere.command-light-text-v14:7:4k             | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Command Light                  | cohere.command-light-text-v14                  | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Embed English                  | cohere.embed-english-v3:0:512                  | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Embed English                  | cohere.embed-english-v3                        | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Embed Multilingual             | cohere.embed-multilingual-v3:0:512             | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Embed Multilingual             | cohere.embed-multilingual-v3                   | TEXT               | EMBEDDING           |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 Chat 13B               | meta.llama2-13b-chat-v1:0:4k                   | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 Chat 13B               | meta.llama2-13b-chat-v1                        | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 Chat 70B               | meta.llama2-70b-chat-v1:0:4k                   | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 Chat 70B               | meta.llama2-70b-chat-v1                        | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 13B                    | meta.llama2-13b-v1:0:4k                        | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 13B                    | meta.llama2-13b-v1                             | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 70B                    | meta.llama2-70b-v1:0:4k                        | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 2 70B                    | meta.llama2-70b-v1                             | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 3 8B Instruct            | meta.llama3-8b-instruct-v1:0                   | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Llama 3 70B Instruct           | meta.llama3-70b-instruct-v1:0                  | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Mistral 7B Instruct            | mistral.mistral-7b-instruct-v0:2               | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Mixtral 8x7B Instruct          | mistral.mixtral-8x7b-instruct-v0:1             | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Mistral Large (2402)           | mistral.mistral-large-2402-v1:0                | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n",
      "| Mistral Small                  | mistral.mistral-small-2402-v1:0                | TEXT               | TEXT                |\n",
      "+--------------------------------+------------------------------------------------+--------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Create a client for Bedrock\n",
    "client = boto3.client('bedrock', region_name='us-east-1')  # Replace with your region\n",
    "\n",
    "# Call an API to list available models\n",
    "response = client.list_foundation_models()\n",
    "\n",
    "# Print the available models with modalities as strings\n",
    "table_data = [[\n",
    "    model['modelName'],\n",
    "    model['modelId'],\n",
    "    ', '.join(model['inputModalities']),\n",
    "    ', '.join(model['outputModalities'])\n",
    "] for model in response['modelSummaries']]\n",
    "\n",
    "print(tabulate(table_data, headers=['Model Name', 'Model ID', 'Input Modalities', 'Output Modalities'], tablefmt='grid', colalign=('left', 'left')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902e048",
   "metadata": {},
   "source": [
    "## Chat models vs LLM in Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d11c9c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding: 15px; border-radius: 10px;\">\n",
    "  <p><b>LangChain</b> offers two simple interfaces to interact with any LLM API provider:</p>\n",
    "  \n",
    "  <ul>\n",
    "    <li><b>LLMs</b></li>\n",
    "    <li><b>Chat models</b></li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd40b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five highly recommended books on Deep Learning:\n",
      "\n",
      "1. \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville: This book is a comprehensive and in-depth guide to deep learning, covering topics such as neural networks, convolutional neural networks, recurrent neural networks, and deep reinforcement learning. It is widely regarded as one of the best resources for understanding the theoretical foundations of deep learning.\n",
      "\n",
      "2. \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by Aurélien Géron: This book provides a practical introduction to machine learning and deep learning using Python and popular libraries such as Scikit-Learn, Keras, and TensorFlow. It covers a wide range of topics, from basic machine learning concepts to advanced deep learning techniques, and includes many examples and exercises to help you apply what you've learned.\n",
      "\n",
      "3. \"Neural Networks and Deep Learning\" by Michael Nielsen: This book is an online tutorial that provides a gentle introduction to neural networks and deep learning. It covers the basics of neural networks, including how they work, how to train them, and how to use them for various tasks. It also includes a chapter on deep learning, which covers topics such as convolutional neural networks and recurrent neural networks.\n",
      "\n",
      "4. \"Deep Learning with Python\" by François Chollet: This book is a practical guide to deep learning using Python and the Keras library. It covers a wide range of topics, from basic neural networks to advanced deep learning techniques, and includes many examples and exercises to help you apply what you've learned. It also includes a chapter on using deep learning for natural language processing.\n",
      "\n",
      "5. \"Deep Learning: A Practitioner's Approach\" by Josh Patterson and Adam Gibson: This book provides a practical guide to building and deploying deep learning models using the TensorFlow and Keras libraries. It covers a wide range of topics, from basic neural networks to advanced deep learning techniques, and includes many examples and exercises to help you apply what you've learned. It also includes a chapter on using deep learning for computer vision.\n"
     ]
    }
   ],
   "source": [
    "# Using BedrockLLM (Not Recommended Now)\n",
    "from langchain_aws import BedrockLLM\n",
    "\n",
    "llm = BedrockLLM(model_id=\"amazon.titan-text-premier-v1:0\")\n",
    "\n",
    "prompt = \"What are the best books on Deep Learning? May be top 5\"\n",
    "completion = llm.invoke(prompt)\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aff554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When it comes to linear algebra books, two titles that are highly regarded and widely recommended are:\n",
      "\n",
      "1. \"Linear Algebra and Its Applications\" by Gilbert Strang (5th Edition)\n",
      "This book is often considered one of the best introductory texts on linear algebra. It is known for its clear explanations, well-chosen examples, and its emphasis on the geometric interpretation of linear algebra concepts. Strang's book covers a wide range of topics, including vector spaces, matrices, determinants, eigenvalues and eigenvectors, and applications to various fields.\n",
      "\n",
      "2. \"Linear Algebra Done Right\" by Sheldon Axler\n",
      "This book takes a more theoretical and rigorous approach to linear algebra. It is often recommended for advanced undergraduate or graduate-level students who want a deeper understanding of the subject. Axler's book focuses on developing a solid foundation in linear algebra, with a strong emphasis on proofs and abstract concepts. It covers topics such as vector spaces, linear transformations, inner product spaces, and applications to other areas of mathematics.\n",
      "\n",
      "Both of these books are highly respected and widely used in undergraduate and graduate-level linear algebra courses. Strang's book is often preferred for a more intuitive and application-oriented approach, while Axler's book is favored for its rigor and theoretical depth. The choice between the two may depend on the student's level of mathematical maturity, learning style, and intended application of linear algebra.\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "prompt = \"What are the best books on Linear Algebra? May be top 2\"\n",
    "completion = llm.invoke(prompt)\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6299618b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two of the best and most widely recommended books on Linear Algebra:\n",
      "\n",
      "1. \"Linear Algebra and Its Applications\" by Gilbert Strang (5th Edition, 2016)\n",
      "This book is considered one of the most comprehensive and accessible introductions to linear algebra. It covers a wide range of topics, including matrices, vector spaces, linear transformations, eigenvalues and eigenvectors, and numerical methods. The book is known for its clear explanations, numerous\n"
     ]
    }
   ],
   "source": [
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": .7, \"max_tokens\": 100})\n",
    "\n",
    "prompt = \"What are the best books on Linear Algebra? May be top 2\"\n",
    "completion = llm.invoke(prompt)\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a3443b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'usage': {'prompt_tokens': 22, 'completion_tokens': 100, 'total_tokens': 122},\n",
       " 'stop_reason': 'max_tokens',\n",
       " 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184d313",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9d084",
   "metadata": {},
   "source": [
    "#### General purpose `PromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695b9395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'da1df7ac-ca40-442e-b194-b605fd74c7a1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 11 Sep 2024 19:36:37 GMT', 'content-type': 'application/json', 'content-length': '30408', 'connection': 'keep-alive', 'x-amzn-requestid': 'da1df7ac-ca40-442e-b194-b605fd74c7a1'}, 'RetryAttempts': 0}, 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large', 'modelId': 'amazon.titan-tg1-large', 'modelName': 'Titan Text Large', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0', 'modelId': 'amazon.titan-image-generator-v1:0', 'modelName': 'Titan Image Generator G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1', 'modelId': 'amazon.titan-image-generator-v1', 'modelName': 'Titan Image Generator G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0', 'modelId': 'amazon.titan-image-generator-v2:0', 'modelName': 'Titan Image Generator G1 v2', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED', 'ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-premier-v1:0', 'modelId': 'amazon.titan-text-premier-v1:0', 'modelName': 'Titan Text G1 - Premier', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.olympus-1-lite-v1:0', 'modelId': 'amazon.olympus-1-lite-v1:0', 'modelName': 'Olympus Lite v1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE', 'VIDEO'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['ON_DEMAND', 'PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02', 'modelId': 'amazon.titan-embed-g1-text-02', 'modelName': 'Titan Text Embeddings v2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k', 'modelId': 'amazon.titan-text-lite-v1:0:4k', 'modelName': 'Titan Text G1 - Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1', 'modelId': 'amazon.titan-text-lite-v1', 'modelName': 'Titan Text G1 - Lite', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k', 'modelId': 'amazon.titan-text-express-v1:0:8k', 'modelName': 'Titan Text G1 - Express', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1', 'modelId': 'amazon.titan-text-express-v1', 'modelName': 'Titan Text G1 - Express', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k', 'modelId': 'amazon.titan-embed-text-v1:2:8k', 'modelName': 'Titan Embeddings G1 - Text', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1', 'modelId': 'amazon.titan-embed-text-v1', 'modelName': 'Titan Embeddings G1 - Text', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k', 'modelId': 'amazon.titan-embed-text-v2:0:8k', 'modelName': 'Titan Text Embeddings V2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0', 'modelId': 'amazon.titan-embed-text-v2:0', 'modelName': 'Titan Text Embeddings V2', 'providerName': 'Amazon', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0', 'modelId': 'amazon.titan-embed-image-v1:0', 'modelName': 'Titan Multimodal Embeddings G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1', 'modelId': 'amazon.titan-embed-image-v1', 'modelName': 'Titan Multimodal Embeddings G1', 'providerName': 'Amazon', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['EMBEDDING'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0', 'modelId': 'stability.stable-diffusion-xl-v1:0', 'modelName': 'SDXL 1.0', 'providerName': 'Stability AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1', 'modelId': 'stability.stable-diffusion-xl-v1', 'modelName': 'SDXL 1.0', 'providerName': 'Stability AI', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['IMAGE'], 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct', 'modelId': 'ai21.j2-grande-instruct', 'modelName': 'J2 Grande Instruct', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct', 'modelId': 'ai21.j2-jumbo-instruct', 'modelName': 'J2 Jumbo Instruct', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid', 'modelId': 'ai21.j2-mid', 'modelName': 'Jurassic-2 Mid', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1', 'modelId': 'ai21.j2-mid-v1', 'modelName': 'Jurassic-2 Mid', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra', 'modelId': 'ai21.j2-ultra', 'modelName': 'Jurassic-2 Ultra', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1:0:8k', 'modelId': 'ai21.j2-ultra-v1:0:8k', 'modelName': 'Jurassic-2 Ultra', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1', 'modelId': 'ai21.j2-ultra-v1', 'modelName': 'Jurassic-2 Ultra', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-instruct-v1:0', 'modelId': 'ai21.jamba-instruct-v1:0', 'modelName': 'Jamba-Instruct', 'providerName': 'AI21 Labs', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k', 'modelId': 'anthropic.claude-instant-v1:2:100k', 'modelName': 'Claude Instant', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1', 'modelId': 'anthropic.claude-instant-v1', 'modelName': 'Claude Instant', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k', 'modelId': 'anthropic.claude-v2:0:18k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k', 'modelId': 'anthropic.claude-v2:0:100k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k', 'modelId': 'anthropic.claude-v2:1:18k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k', 'modelId': 'anthropic.claude-v2:1:200k', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1', 'modelId': 'anthropic.claude-v2:1', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2', 'modelId': 'anthropic.claude-v2', 'modelName': 'Claude', 'providerName': 'Anthropic', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:28k', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:200k', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0', 'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0', 'modelName': 'Claude 3 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:48k', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:200k', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0', 'modelId': 'anthropic.claude-3-haiku-20240307-v1:0', 'modelName': 'Claude 3 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:12k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:28k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0:200k', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0', 'modelId': 'anthropic.claude-3-opus-20240229-v1:0', 'modelName': 'Claude 3 Opus', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0:18k', 'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0:18k', 'modelName': 'Claude 3.5 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0:51k', 'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0:51k', 'modelName': 'Claude 3.5 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0:200k', 'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0:200k', 'modelName': 'Claude 3.5 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0', 'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0', 'modelName': 'Claude 3.5 Sonnet', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k', 'modelId': 'cohere.command-text-v14:7:4k', 'modelName': 'Command', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14', 'modelId': 'cohere.command-text-v14', 'modelName': 'Command', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0', 'modelId': 'cohere.command-r-v1:0', 'modelName': 'Command R', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0', 'modelId': 'cohere.command-r-plus-v1:0', 'modelName': 'Command R+', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k', 'modelId': 'cohere.command-light-text-v14:7:4k', 'modelName': 'Command Light', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14', 'modelId': 'cohere.command-light-text-v14', 'modelName': 'Command Light', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512', 'modelId': 'cohere.embed-english-v3:0:512', 'modelName': 'Embed English', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3', 'modelId': 'cohere.embed-english-v3', 'modelName': 'Embed English', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512', 'modelId': 'cohere.embed-multilingual-v3:0:512', 'modelName': 'Embed Multilingual', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3', 'modelId': 'cohere.embed-multilingual-v3', 'modelName': 'Embed Multilingual', 'providerName': 'Cohere', 'inputModalities': ['TEXT'], 'outputModalities': ['EMBEDDING'], 'responseStreamingSupported': False, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1:0:4k', 'modelId': 'meta.llama2-13b-chat-v1:0:4k', 'modelName': 'Llama 2 Chat 13B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['PROVISIONED'], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1', 'modelId': 'meta.llama2-13b-chat-v1', 'modelName': 'Llama 2 Chat 13B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1:0:4k', 'modelId': 'meta.llama2-70b-chat-v1:0:4k', 'modelName': 'Llama 2 Chat 70B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1', 'modelId': 'meta.llama2-70b-chat-v1', 'modelName': 'Llama 2 Chat 70B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k', 'modelId': 'meta.llama2-13b-v1:0:4k', 'modelName': 'Llama 2 13B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1', 'modelId': 'meta.llama2-13b-v1', 'modelName': 'Llama 2 13B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1:0:4k', 'modelId': 'meta.llama2-70b-v1:0:4k', 'modelName': 'Llama 2 70B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': ['FINE_TUNING'], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1', 'modelId': 'meta.llama2-70b-v1', 'modelName': 'Llama 2 70B', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': [], 'modelLifecycle': {'status': 'LEGACY'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0', 'modelId': 'meta.llama3-8b-instruct-v1:0', 'modelName': 'Llama 3 8B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0', 'modelId': 'meta.llama3-70b-instruct-v1:0', 'modelName': 'Llama 3 70B Instruct', 'providerName': 'Meta', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2', 'modelId': 'mistral.mistral-7b-instruct-v0:2', 'modelName': 'Mistral 7B Instruct', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1', 'modelId': 'mistral.mixtral-8x7b-instruct-v0:1', 'modelName': 'Mixtral 8x7B Instruct', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0', 'modelId': 'mistral.mistral-large-2402-v1:0', 'modelName': 'Mistral Large (2402)', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}, {'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0', 'modelId': 'mistral.mistral-small-2402-v1:0', 'modelName': 'Mistral Small', 'providerName': 'Mistral AI', 'inputModalities': ['TEXT'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['ON_DEMAND'], 'modelLifecycle': {'status': 'ACTIVE'}}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Give me a one line definition of {word} with {num} of examples\")\n",
    "prompt = prompt_template.format(word=\"flabbergasted\", num=2)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02d4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flabbergasted means to be utterly astonished or astounded, as in \"She was flabbergasted when she won the lottery jackpot\" or \"The magician's trick left the audience flabbergasted.\"\n"
     ]
    }
   ],
   "source": [
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "completion = llm.invoke(prompt)\n",
    "\n",
    "print(completion.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9687ca7",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding: 15px; border-radius: 10px; border-left: 6px solid #4682B4;\">\n",
    "  <p>Alternatively, the <b>Chat Model interface</b> enables back-and-forth conversations between the user and the model. This interface is separate because popular LLM providers, like OpenAI, differentiate messages into <b>user</b>, <b>assistant</b>, and <b>system roles</b>, which define the type of content each message contains:</p>\n",
    "  \n",
    "  <ul>\n",
    "    <li><b>System role:</b> Specifies instructions the model should use to answer a user question.</li>\n",
    "    <li><b>User role:</b> The individual asking questions and generating queries sent to the model.</li>\n",
    "    <li><b>Assistant role:</b> The model’s responses to the user’s query.</li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4011aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "prompt = [HumanMessage(content=\"What is the capital of India?\")]\n",
    "completion = llm.invoke(prompt)\n",
    "\n",
    "print(completion.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd381b80",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding: 15px; border-radius: 10px; border-left: 6px solid #4682B4;\">\n",
    "  <p>Instead of a single prompt string, <b>chat models</b> use different types of chat message interfaces, each associated with a specific role:</p>\n",
    "  \n",
    "  <ul>\n",
    "    <li><b>HumanMessage:</b> Sent from the human's perspective, with the user role.</li>\n",
    "    <li><b>AIMessage:</b> Sent from the AI's perspective, with the assistant role.</li>\n",
    "    <li><b>SystemMessage:</b> Provides instructions the AI should follow, with the system role.</li>\n",
    "    <li><b>ChatMessage:</b> Allows arbitrary role setting.</li>\n",
    "  </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5961a967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Barack Obama was the president of the United States in 2010. He served two terms from 2009 to 2017. Why was the baseball player so cool? Because he had a great pitch!', additional_kwargs={'usage': {'prompt_tokens': 35, 'completion_tokens': 46, 'total_tokens': 81}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 35, 'completion_tokens': 46, 'total_tokens': 81}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7cf0903d-3761-4cc3-936a-3672489bc42d-0', usage_metadata={'input_tokens': 35, 'output_tokens': 46, 'total_tokens': 81})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": .7, \"max_tokens\": 100})\n",
    "\n",
    "prompt = [\n",
    "            SystemMessage(content=\"You are a helpful assistant that answers questions with a joke at the end.\"),\n",
    "            HumanMessage(content=\"Who was the president of the United States in 2010?\")\n",
    "         ]\n",
    "completion = llm.invoke(prompt)\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1a47f5",
   "metadata": {},
   "source": [
    "As you can see, the model obeyed the instruction provided in the SystemMessage even though it wasn’t present in the user’s question. This enables you to pre-configure your AI application to respond in a relatively predictable manner based on the user’s input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f33be1",
   "metadata": {},
   "source": [
    "#### Using `ChatPromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b32948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that gives a one-line definition of the word entered by user'),\n",
       " HumanMessage(content='Sesquipedalian')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that gives a one-line definition of the word entered by user\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(user_input=\"Sesquipedalian\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b3a355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sesquipedalian means using long words unnecessarily.', additional_kwargs={'usage': {'prompt_tokens': 31, 'completion_tokens': 16, 'total_tokens': 47}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 31, 'completion_tokens': 16, 'total_tokens': 47}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-ab557c17-a704-4937-aadd-1a66cfbdd83b-0', usage_metadata={'input_tokens': 31, 'output_tokens': 16, 'total_tokens': 47})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c86e77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that gives a one-line answer to user query'),\n",
       " HumanMessage(content='Who created theory of relativity?'),\n",
       " AIMessage(content='Albert Einstein developed the theory of relativity.'),\n",
       " HumanMessage(content='When was it created?')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that gives a one-line answer to user query\"),\n",
    "        (\"human\", \"Who created theory of relativity?\"),\n",
    "        (\"ai\", \"Albert Einstein developed the theory of relativity.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(user_input=\"When was it created?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ff20b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The theory of relativity was developed by Einstein in the early 20th century.', additional_kwargs={'usage': {'prompt_tokens': 49, 'completion_tokens': 20, 'total_tokens': 69}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 49, 'completion_tokens': 20, 'total_tokens': 69}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-2dd3225a-6463-42cb-a672-af6e1e19fe44-0', usage_metadata={'input_tokens': 49, 'output_tokens': 20, 'total_tokens': 69})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2445ce",
   "metadata": {},
   "source": [
    "## Getting Specific Formats out of LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192a2371",
   "metadata": {},
   "source": [
    "Plain text outputs are useful, but there may be use cases where you need the LLM to generate a structured output, that is, output in a machine-readable format, such as JSON, XML or CSV, or even in a programming language such as Python or JavaScript. This is very useful when you intend to hand that output off to some other piece of code, making an LLM play a part in your larger application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ebdf1",
   "metadata": {},
   "source": [
    "#### JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a7c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie(title='Interstellar', director='Christopher Nolan', release_year=2014, description='Interstellar is a 2014 science fiction film directed by Christopher Nolan. It depicts a crew of astronauts who travel through a newly discovered wormhole in search of habitable planets for humanity to colonize, as life on Earth is becoming unsustainable. The film stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, and Michael Caine, and received widespread critical acclaim for its visuals, musical score, and exploration of scientific theories like relativity and wormholes.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title: str = Field(description=\"The title of the movie\")\n",
    "    director: str = Field(description=\"The director of the movie\")\n",
    "    release_year: int = Field(description=\"The year the movie was released\")\n",
    "    description: str = Field(description=\"A brief description of the movie\")\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": .1})\n",
    "structured_llm = llm.with_structured_output(Movie)\n",
    "\n",
    "prompt = [HumanMessage(content=\"What is a highly acclaimed science fiction movie?\")]\n",
    "completion = structured_llm.invoke(prompt)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9c95947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One highly acclaimed science fiction movie is \"Interstellar\" directed by Christopher Nolan.\\n\\nSome key details about Interstellar:\\n\\n- Released in 2014\\n- Stars Matthew McConaughey, Anne Hathaway, Jessica Chastain\\n- About a crew of astronauts who travel through a newly discovered wormhole in search of habitable planets to replace a dying Earth\\n- Known for its scientifically accurate depiction of concepts like black holes, relativity, and theoretical physics\\n- Acclaimed for its visuals, score, and emotional storytelling\\n- Won the Academy Award for Best Visual Effects\\n- Considered one of Christopher Nolan\\'s best and most ambitious films\\n\\nOther highly regarded sci-fi movies include \"2001: A Space Odyssey,\" \"Blade Runner,\" \"The Matrix,\" \"Arrival,\" and \"Inception.\" But \"Interstellar\" stands out for its grand scale, scientific authenticity, and Nolan\\'s directorial vision.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f820a2",
   "metadata": {},
   "source": [
    "## Chain and LangChain Expressions Language (LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9beb639",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding: 15px; border-radius: 10px; border-left: 6px solid #4682B4;\">\n",
    "  <p><b>LangChain Expression Language (LCEL)</b> is a declarative language for composing LangChain components. LangChain compiles LCEL compositions into an optimized execution plan, offering automatic parallelization, streaming, tracing, and async support.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d3e2f",
   "metadata": {},
   "source": [
    "#### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d7057a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city you're visiting:  NYC\n",
      "Enter the month of your visit:  Dec\n",
      "Enter the local language:  English\n",
      "Enter your budget (low/medium/high):  medium\n",
      "Enter any specific questions or requests:  Adventure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some adventurous things to do in NYC in December:\n",
      "\n",
      "1. Must-Visit Attractions:\n",
      "- Take a walking tour across the Brooklyn Bridge for amazing skyline views\n",
      "- Go ice skating at iconic rinks like Rockefeller Center or Bryant Park\n",
      "- Visit the Top of the Rock observation deck for panoramic city views\n",
      "\n",
      "2. Local Cuisine:\n",
      "- Try a classic NYC pizza slice from places like Joe's Pizza or Prince Street Pizza\n",
      "- Get bagels and lox (cured salmon) from a legendary bagel shop like Russ & Daughters\n",
      "- Sample global street foods from vendors and food trucks\n",
      "\n",
      "3. Useful English Phrases:\n",
      "- \"Can you give me directions to...\"\n",
      "- \"How much is the admission/cover charge?\"\n",
      "- \"Where is the nearest subway station?\"\n",
      "\n",
      "4. Budget Travel Tips:\n",
      "- Use the affordable subway system to get around \n",
      "- Look for free days/times at top museums and attractions\n",
      "- Eat at casual delis, diners, and food trucks for cheap eats\n",
      "- Consider the NYC City Pass for bundled attraction discounts\n",
      "\n",
      "With its endless energy and variety of experiences, NYC is perfect for an adventurous urban getaway in December!\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": .1})\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a travel guide. Welcome to the {city} travel guide!\n",
    "        If you're visiting in {month}, here's what you can do:\n",
    "        1. Must-visit attractions.\n",
    "        2. Local cuisine you must try.\n",
    "        3. Useful phrases in {language}.\n",
    "        4. Tips for traveling on a {budget} budget.\n",
    "        Enjoy your trip!\"\"\"),\n",
    "        (\"human\", \"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# Get user input\n",
    "city = input(\"Enter the city you're visiting: \")\n",
    "month = input(\"Enter the month of your visit: \")\n",
    "language = input(\"Enter the local language: \")\n",
    "budget = input(\"Enter your budget (low/medium/high): \")\n",
    "user_input = input(\"Enter any specific questions or requests: \")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"city\": city,\n",
    "    \"month\": month,\n",
    "    \"language\": language,\n",
    "    \"budget\": budget,\n",
    "    \"user_input\": user_input\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a21194",
   "metadata": {},
   "source": [
    "#### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47beefc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the topic:  Linear Regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Mastering Linear Regression: A Comprehensive Guide\n",
      "\n",
      "Introduction:\n",
      "\n",
      "In the realm of data analysis and machine learning, linear regression stands as a fundamental and widely-used technique for modeling the relationship between variables. Whether you're a data scientist, a researcher, or simply someone curious about the world of predictive modeling, understanding linear regression is essential. This blog post aims to provide a comprehensive guide to linear regression, exploring its definition, applications, underlying assumptions, and techniques for building, evaluating, and improving linear regression models.\n",
      "\n",
      "Linear regression is a statistical method that establishes a linear relationship between a dependent variable (often referred to as the target or response variable) and one or more independent variables (also known as predictors or features). Its purpose is to identify the best-fitting line or hyperplane that describes the relationship between these variables, enabling predictions and facilitating data-driven decision-making.\n",
      "\n",
      "The applications of linear regression are widespread, spanning various fields such as economics, finance, engineering, social sciences, and many more. From predicting stock prices based on historical data to estimating energy consumption based on building characteristics, linear regression has proven invaluable in uncovering insights and making informed decisions.\n",
      "\n",
      "In this blog post, we will delve into the intricacies of linear regression, starting with its fundamental concepts and progressing towards more advanced techniques for model improvement and validation. Whether you're a beginner seeking to grasp the basics or an experienced practitioner aiming to expand your knowledge, this guide will provide a comprehensive understanding of this powerful analytical tool.\n"
     ]
    }
   ],
   "source": [
    "# Generate a sequential chain with multiple chain for a blog generator\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "title_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a professional blogger.\n",
    "        Create an outline for a blog post on the following topic: {topic}\n",
    "        The outline should include:\n",
    "        - 3 main points with subpoints\n",
    "        - Conclusion\n",
    "        Answer with the outline only, no additional text.\"\"\"),\n",
    "        (\"human\", \"{topic}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "introduction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a professional blogger.\n",
    "        Write an engaging introduction paragraph based on the following\n",
    "        outline:{outline}\n",
    "        The introduction should hook the reader and provide a brief\n",
    "        overview of the topic Also add the title of the blog post\"\"\"),\n",
    "        (\"human\", \"{outline}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "first_chain = title_prompt | llm | StrOutputParser() \n",
    "second_chain = introduction_prompt | llm | StrOutputParser()\n",
    "final_chain = (\n",
    "                {\"topic\": lambda x: x, \"outline\": first_chain} \n",
    "                | introduction_prompt \n",
    "                | llm \n",
    "                | StrOutputParser()\n",
    "            )\n",
    "\n",
    "topic = input(\"Enter the topic: \")\n",
    "response = final_chain.invoke(topic)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc55a38",
   "metadata": {},
   "source": [
    "## Memory: Learn from Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e65ea",
   "metadata": {},
   "source": [
    "#### Adding messages to memory with `ConversationBufferMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0178ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from pprint import pprint\n",
    "\n",
    "sample_memory = ConversationBufferMemory(memory_key=\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d379ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d47e7f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: What's the capital of France?\\n\"\n",
      "            'AI: The capital of France is Paris.'}\n"
     ]
    }
   ],
   "source": [
    "sample_memory.chat_memory.add_user_message(\"What's the capital of France?\")\n",
    "sample_memory.chat_memory.add_ai_message(\"The capital of France is Paris.\")\n",
    "\n",
    "# Let's check the contents of the memory\n",
    "pprint(sample_memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d601e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: What's the capital of France?\\n\"\n",
      "            'AI: The capital of France is Paris.\\n'\n",
      "            \"Human: What's the capital of India?\\n\"\n",
      "            'AI: The capital of India is New Delhi.'}\n"
     ]
    }
   ],
   "source": [
    "sample_memory.chat_memory.add_user_message(\"What's the capital of India?\")\n",
    "sample_memory.chat_memory.add_ai_message(\"The capital of India is New Delhi.\")\n",
    "\n",
    "# Let's check the contents of the memory\n",
    "pprint(sample_memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a2e97",
   "metadata": {},
   "source": [
    "#### `ConversationBufferMemory` with `LLMChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27c21aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a knowledgeable food expert having a chat with a human about world cuisines.\n",
      "    Previous chat: []\n",
      "    Human: What's a popular dish in Italian cuisine?\n",
      "    Food Expert: \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/qf1dw3cs4q5007gb2_9zd8600000gr/T/ipykernel_40678/1966144164.py:18: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory, verbose=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Here are some of the most popular and iconic dishes in Italian cuisine:\n",
      "\n",
      "• Pizza Napoletana - The classic Neapolitan pizza with tomato sauce, mozzarella cheese, and fresh basil. Naples is considered the birthplace of pizza.\n",
      "\n",
      "• Pasta Bolognese - Pasta with a rich, meaty ragù (meat-based sauce) made with beef, vegetables and tomatoes. It originated in Bologna.\n",
      "\n",
      "• Lasagna alla Bolognese - Layers of pasta with Bolognese ragù, béchamel sauce and cheese, also from Bologna.\n",
      "\n",
      "• Risotto alla Milanese - A creamy Arborio rice dish flavored with saffron, from Milan. Other popular risotto varieties include mushroom and seafood.\n",
      "\n",
      "• Ossobuco alla Milanese - Cross-cut veal shanks braised with wine, vegetables and broth, from Lombardy. \n",
      "\n",
      "• Saltimbocca alla Romana - Thin veal cutlets with prosciutto and sage, a classic Roman dish.\n",
      "\n",
      "• Tiramisù - The famous coffee-flavored dessert made with ladyfingers, mascarpone cheese and cocoa powder.\n",
      "\n",
      "Italian cuisine showcases incredible regional diversity while highlighting simple, high-quality ingredients prepared with decades or centuries of tradition behind the dishes. Pastas, pizzas, risottos and slow-cooked meat dishes are iconic staples.\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\"],\n",
    "    template=\"\"\"You are a knowledgeable food expert having a chat with a human about world cuisines.\n",
    "    Previous chat: {history}\n",
    "    Human: {human_input}\n",
    "    Food Expert: \"\"\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(input_key=\"human_input\", memory_key=\"history\", return_messages=True)\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory, verbose=True)\n",
    "\n",
    "# First question\n",
    "response1 = chain.invoke({\"human_input\": \"What's a popular dish in Italian cuisine?\"})\n",
    "print(response1['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "385ad693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a knowledgeable food expert having a chat with a human about world cuisines.\n",
      "    Previous chat: [HumanMessage(content=\"What's a popular dish in Italian cuisine?\"), AIMessage(content='Here are some of the most popular and iconic dishes in Italian cuisine:\\n\\n• Pizza Napoletana - The classic Neapolitan pizza with tomato sauce, mozzarella cheese, and fresh basil. Naples is considered the birthplace of pizza.\\n\\n• Pasta Bolognese - Pasta with a rich, meaty ragù (meat-based sauce) made with beef, vegetables and tomatoes. It originated in Bologna.\\n\\n• Lasagna alla Bolognese - Layers of pasta with Bolognese ragù, béchamel sauce and cheese, also from Bologna.\\n\\n• Risotto alla Milanese - A creamy Arborio rice dish flavored with saffron, from Milan. Other popular risotto varieties include mushroom and seafood.\\n\\n• Ossobuco alla Milanese - Cross-cut veal shanks braised with wine, vegetables and broth, from Lombardy. \\n\\n• Saltimbocca alla Romana - Thin veal cutlets with prosciutto and sage, a classic Roman dish.\\n\\n• Tiramisù - The famous coffee-flavored dessert made with ladyfingers, mascarpone cheese and cocoa powder.\\n\\nItalian cuisine showcases incredible regional diversity while highlighting simple, high-quality ingredients prepared with decades or centuries of tradition behind the dishes. Pastas, pizzas, risottos and slow-cooked meat dishes are iconic staples.')]\n",
      "    Human: What's the main ingredient in this dish?\n",
      "    Food Expert: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Could you please specify which Italian dish you are asking about? I covered several popular Italian dishes in my previous response, so clarifying which one you need the main ingredient for would help me provide an accurate answer.\n"
     ]
    }
   ],
   "source": [
    "# Second question\n",
    "response2 = chain.invoke({\"human_input\": \"What's the main ingredient in this dish?\"})\n",
    "print(response2['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "204586bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a knowledgeable food expert having a chat with a human about world cuisines.\n",
      "Human: What's the most popular dish in Italian cuisine? Pick only one.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "If I had to pick just one dish as the most popular in Italian cuisine, I would say pizza.\n",
      "\n",
      "Pizza is an iconic Italian food that has achieved immense global popularity. Its origins can be traced back to Naples, where the modern pizza we know today was developed in the late 18th or early 19th century. The combination of a thin crust, tomato sauce, and fresh mozzarella cheese became the classic Neapolitan pizza that captured the world's imagination.\n",
      "\n",
      "While there are now countless variations, the simple Margherita pizza (named after the Queen consort of Italy, Margherita of Savoy) with just tomato, mozzarella, and basil remains one of the most beloved versions. Pizza has become so ingrained in Italian culture and cuisine that it's hard to imagine the country's food scene without it.\n",
      "\n",
      "Whether enjoyed as a quick street food, at a family gathering, or an upscale pizzeria, pizza transcends social classes in Italy. Its popularity has also spread globally with Italian immigrant communities helping to popularize it worldwide. So while pasta dishes, risottos, and other classics are hugely popular too, I'd argue that the iconic pizza is the most quintessentially popular Italian dish.\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Create the prompt template using ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"You are a knowledgeable food expert having a chat with a human about world cuisines.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"my_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{human_input}\"),\n",
    "])\n",
    "\n",
    "# Set up memory\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"my_history\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "# Create the chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory, verbose=True)\n",
    "\n",
    "# First question\n",
    "response1 = chain.invoke({\"human_input\": \"What's the most popular dish in Italian cuisine? Pick only one.\"})\n",
    "print(response1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a81c12d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a knowledgeable food expert having a chat with a human about world cuisines.\n",
      "Human: What's the most popular dish in Italian cuisine? Pick only one.\n",
      "AI: If I had to pick just one dish as the most popular in Italian cuisine, I would say pizza.\n",
      "\n",
      "Pizza is an iconic Italian food that has achieved immense global popularity. Its origins can be traced back to Naples, where the modern pizza we know today was developed in the late 18th or early 19th century. The combination of a thin crust, tomato sauce, and fresh mozzarella cheese became the classic Neapolitan pizza that captured the world's imagination.\n",
      "\n",
      "While there are now countless variations, the simple Margherita pizza (named after the Queen consort of Italy, Margherita of Savoy) with just tomato, mozzarella, and basil remains one of the most beloved versions. Pizza has become so ingrained in Italian culture and cuisine that it's hard to imagine the country's food scene without it.\n",
      "\n",
      "Whether enjoyed as a quick street food, at a family gathering, or an upscale pizzeria, pizza transcends social classes in Italy. Its popularity has also spread globally with Italian immigrant communities helping to popularize it worldwide. So while pasta dishes, risottos, and other classics are hugely popular too, I'd argue that the iconic pizza is the most quintessentially popular Italian dish.\n",
      "Human: What's the main ingredient in this dish?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The main ingredient in pizza is flour, which is used to make the dough for the pizza crust.\n",
      "\n",
      "Traditionally, Italian pizza doughs are made from simple ingredients:\n",
      "\n",
      "- Flour - Usually a high-protein bread flour or '00' finely milled Italian flour is used to get the right chewy, crispy texture.\n",
      "\n",
      "- Water\n",
      "- Yeast - Often fresh cake yeast, though dry active yeast can be used too.\n",
      "- Salt\n",
      "\n",
      "So flour is the core, foundational ingredient that forms the base of the pizza. The proteins in the wheat flour are what allows the dough to develop gluten strands and achieve that characteristic chewy yet crispy texture when baked at high heat.\n",
      "\n",
      "Other popular pizza ingredients like tomato sauce, cheese, herbs, meats etc. are toppings added on top of the flour-based dough foundation. But flour is truly the main ingredient, comprising usually 50-60% of the dough's total weight and binding all the other dough components together.\n",
      "\n",
      "No other single ingredient plays as crucial a role in pizza's taste, texture and overall structure as flour does for crafting the ideal pizza crust.\n"
     ]
    }
   ],
   "source": [
    "# Second question\n",
    "response2 = chain.invoke({\"human_input\": \"What's the main ingredient in this dish?\"})\n",
    "print(response2['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70fc55e",
   "metadata": {},
   "source": [
    "#### `ConversationBufferMemory` With `ConversationChain`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64f65e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: What's the most popular dish in Italian cuisine?\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sg/qf1dw3cs4q5007gb2_9zd8600000gr/T/ipykernel_40678/997765492.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
      "  chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"What's the most popular dish in Italian cuisine?\", 'history': '', 'response': \"Hmm, that's a great question! Italian cuisine is so rich and varied that it's hard to pinpoint one single most popular dish. Some contenders that come to mind are:\\n\\nPizza - This iconic flatbread with tomato sauce and mozzarella cheese originated in Naples and has become one of the most beloved Italian foods around the world. There are endless varieties from the classic Margherita to creative gourmet toppings.\\n\\nPasta - Pasta dishes like spaghetti bolognese, carbonara, and lasagna are quintessential Italian comfort foods enjoyed across the country and internationally. Each region has its own specialties when it comes to pasta shapes and sauces.\\n\\nRisotto - This creamy rice dish cooked with broth originated in northern Italy. Popular varieties include risotto alla milanese with saffron and risotto ai funghi with mushrooms.\\n\\nTiramisu - For dessert, the layered coffee-flavored cake tiramisu is an iconic national sweet treat.\\n\\nIt's hard to definitively name one single most popular dish since Italian food is so regionally diverse. But those are some of the iconic staples that come to mind. Let me know if you have a personal favorite!\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory=memory, verbose=True)\n",
    "\n",
    "response = chain.invoke({\"input\": \"What's the most popular dish in Italian cuisine?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a853b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be6f6a",
   "metadata": {},
   "source": [
    "#### `ConversationBufferMemory` With `RunnableWithMessageHistory`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba3d9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photosynthesis is the process by which plants and some other organisms convert light energy from the sun into chemical energy in the form of glucose (sugar) and oxygen. It occurs in the chloroplasts of plant cells.\n",
      "\n",
      "The overall equation for photosynthesis is:\n",
      "\n",
      "6CO2 + 6H2O + Sunlight Energy → C6H12O6 + 6O2\n",
      "\n",
      "Where:\n",
      "- CO2 is carbon dioxide\n",
      "- H2O is water\n",
      "- C6H12O6 is glucose\n",
      "- O2 is oxygen\n",
      "\n",
      "The process involves two main stages:\n",
      "\n",
      "1) The Light Reactions: During this stage, light energy is absorbed and used to split water molecules into electrons, hydrogen ions, and oxygen gas. This provides the energy carrier molecules ATP and NADPH.\n",
      "\n",
      "2) The Calvin Cycle: This stage doesn't directly use sunlight. It takes the ATP, NADPH, and carbon dioxide from the atmosphere and uses enzymes to produce glucose molecules. This is the photosynthetic carbon fixation phase.\n",
      "\n",
      "Oxygen released during photosynthesis comes from splitting water molecules during the light reactions. Plants and algae produce most of the oxygen in the Earth's atmosphere through photosynthesis.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "# Create the runnable\n",
    "runnable = prompt | llm\n",
    "\n",
    "store = {} \n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap the chain with message history\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "# Use the chain\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"What is photosynthesis?\"},\n",
    "    config={'configurable': {'session_id': 'session_1'}}\n",
    ")\n",
    "print(response1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me explain photosynthesis in simpler terms:\n",
      "\n",
      "Photosynthesis is how plants make their own food (glucose/sugar) using sunlight, water and carbon dioxide from the air.\n",
      "\n",
      "It happens in the green parts of plants, mainly the leaves, which contain a green pigment called chlorophyll.\n",
      "\n",
      "During photosynthesis:\n",
      "\n",
      "1) The plant absorbs light energy from the sun.\n",
      "\n",
      "2) It takes in carbon dioxide from the air through tiny pores in its leaves. \n",
      "\n",
      "3) It also takes in water from the soil through its roots.\n",
      "\n",
      "4) Using the energy from sunlight, the plant combines the carbon dioxide and water to produce glucose (food for the plant) and releases oxygen as a byproduct.\n",
      "\n",
      "5) The oxygen is released out into the air through the leaf pores.\n",
      "\n",
      "So in simple terms - plants use sunlight, carbon dioxide and water to produce their food (glucose) and release oxygen in the process, which humans and animals need to breathe.\n",
      "\n",
      "Does this help explain what photosynthesis is in an easier to understand way? Let me know if you need any clarification.\n"
     ]
    }
   ],
   "source": [
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What?\"},\n",
    "    config={'configurable': {'session_id': 'session_1'}}\n",
    ")\n",
    "print(response2.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed759601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, let me try to explain photosynthesis in the simplest way possible:\n",
      "\n",
      "Photosynthesis is like a plant's way of cooking its own food.\n",
      "\n",
      "Just like we need ingredients to cook food in the kitchen, plants need three main \"ingredients\" for photosynthesis:\n",
      "\n",
      "1) Sunlight - This provides the energy/heat for \"cooking.\"\n",
      "2) Water - Plants take this up from the soil through their roots.\n",
      "3) Carbon dioxide - Plants take this gas from the air through their leaves.\n",
      "\n",
      "Using the energy from sunlight, plants mix the water and carbon dioxide together inside their leaves to make a sugar called glucose. Glucose is the \"food\" that gives plants energy to grow.\n",
      "\n",
      "But when plants \"cook\" this glucose food, they also make a leftover \"ingredient\" that they don't need - oxygen gas. So plants release this oxygen back out into the air through tiny holes in their leaves.\n",
      "\n",
      "This oxygen is very important for animals and humans to breathe.\n",
      "\n",
      "So in simple terms - plants use sunlight, water and air (carbon dioxide) to make their food (glucose), and give out oxygen as a leftover ingredient.\n",
      "\n",
      "Let me know if this super simple cooking analogy for photosynthesis makes more sense!\n"
     ]
    }
   ],
   "source": [
    "response3 = chain_with_history.invoke(\n",
    "    {\"input\": \"What still can't get it? Can you explain it in a simpler way?\"},\n",
    "    config={'configurable': {'session_id': 'session_1'}}\n",
    ")\n",
    "print(response3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed310126",
   "metadata": {},
   "source": [
    "#### `ConversationBufferWindowMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fb9d5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the capital of India?',\n",
       " 'history': '',\n",
       " 'response': \"The capital of India is New Delhi.\\n\\nNew Delhi is a city located in northern India and serves as the capital of the country. It is one of the largest cities in India with a population of over 29 million in the greater metropolitan area.\\n\\nSome key facts about New Delhi:\\n\\n- It has been the official capital of India since 1912 when the British moved the capital from Calcutta (now Kolkata).\\n\\n- It is home to many important government buildings and monuments like the Indian Parliament, Rashtrapati Bhavan (the Presidential Palace), India Gate war memorial, and more.\\n\\n- It encompasses two distinct areas - New Delhi which is the planned city designed by British architects, and Old Delhi which is the ancient walled city dating back centuries.\\n\\n- Major attractions include the Red Fort, Jama Masjid mosque, Chandni Chowk market, Qutub Minar tower, Humayun's Tomb and others.\\n\\n- It has an international airport connecting the city to the rest of India and the world.\\n\\nSo in summary, while there are many important cities in India, New Delhi stands out as the official, political capital and seat of the central government. Let me know if you need any other details!\"}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "convo_chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "convo_chain.invoke({\"input\": \"Whats the capital of India?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2028f124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the capital of France?',\n",
       " 'history': \"Human: Whats the capital of India?\\nAI: The capital of India is New Delhi.\\n\\nNew Delhi is a city located in northern India and serves as the capital of the country. It is one of the largest cities in India with a population of over 29 million in the greater metropolitan area.\\n\\nSome key facts about New Delhi:\\n\\n- It has been the official capital of India since 1912 when the British moved the capital from Calcutta (now Kolkata).\\n\\n- It is home to many important government buildings and monuments like the Indian Parliament, Rashtrapati Bhavan (the Presidential Palace), India Gate war memorial, and more.\\n\\n- It encompasses two distinct areas - New Delhi which is the planned city designed by British architects, and Old Delhi which is the ancient walled city dating back centuries.\\n\\n- Major attractions include the Red Fort, Jama Masjid mosque, Chandni Chowk market, Qutub Minar tower, Humayun's Tomb and others.\\n\\n- It has an international airport connecting the city to the rest of India and the world.\\n\\nSo in summary, while there are many important cities in India, New Delhi stands out as the official, political capital and seat of the central government. Let me know if you need any other details!\",\n",
       " 'response': 'The capital of France is Paris.\\n\\nParis is one of the most famous and iconic cities in the world. Some key facts about Paris:\\n\\n- It has been the capital of France since the late 6th century during the reign of the Merovingian kings.\\n\\n- It is located in the Île-de-France region in the north-central part of the country, straddling the Seine river.\\n\\n- With a population of over 2 million in the city proper and nearly 12 million in the larger metropolitan area, it is one of the most populous cities in Europe.\\n\\n- Major landmarks include the Eiffel Tower, the Louvre museum, the Notre-Dame Cathedral, the Arc de Triomphe, the Champs-Élysées avenue and many more.\\n\\n- It is an global center for art, fashion, gastronomy, and culture. The Louvre is the most visited art museum in the world.\\n\\n- Paris hosts the annual French Open tennis tournament at Roland Garros stadium.\\n\\n- The city has a very atmospheric and romantic reputation, being referred to as the \"City of Light\" and the \"City of Love.\"\\n\\nSo in summary, as the enduring capital through centuries of French history and a world city of culture and romance, Paris occupies a special place for both France and the world at large. Let me know if you need any other details!'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_chain.invoke({\"input\": \"Whats the capital of France?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ca225db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the capital of Italy?',\n",
       " 'history': 'Human: Whats the capital of France?\\nAI: The capital of France is Paris.\\n\\nParis is one of the most famous and iconic cities in the world. Some key facts about Paris:\\n\\n- It has been the capital of France since the late 6th century during the reign of the Merovingian kings.\\n\\n- It is located in the Île-de-France region in the north-central part of the country, straddling the Seine river.\\n\\n- With a population of over 2 million in the city proper and nearly 12 million in the larger metropolitan area, it is one of the most populous cities in Europe.\\n\\n- Major landmarks include the Eiffel Tower, the Louvre museum, the Notre-Dame Cathedral, the Arc de Triomphe, the Champs-Élysées avenue and many more.\\n\\n- It is an global center for art, fashion, gastronomy, and culture. The Louvre is the most visited art museum in the world.\\n\\n- Paris hosts the annual French Open tennis tournament at Roland Garros stadium.\\n\\n- The city has a very atmospheric and romantic reputation, being referred to as the \"City of Light\" and the \"City of Love.\"\\n\\nSo in summary, as the enduring capital through centuries of French history and a world city of culture and romance, Paris occupies a special place for both France and the world at large. Let me know if you need any other details!',\n",
       " 'response': 'The capital of Italy is Rome.\\n\\nHere are some key details about Rome:\\n\\n- Rome has been the capital city of Italy since 1871, after previously serving as the capital of the Roman Kingdom, Roman Republic and Roman Empire.\\n\\n- It is located in the central-western portion of the Italian peninsula, on the Tiber river.\\n\\n- With around 2.9 million residents in the city proper and over 4 million in the greater metropolitan area, Rome is Italy\\'s largest and most populous city.\\n\\n- Rome is renowned for its rich history spanning over two and a half thousand years. It was once the center of the Roman Empire that ruled the Mediterranean world.\\n\\n- The city is home to numerous iconic historical sites including the Colosseum, Roman Forum, Pantheon, Trevi Fountain, Spanish Steps, and the Vatican City (an independent state within Rome).\\n\\n- St. Peter\\'s Basilica in the Vatican is the largest church in the world. The Vatican Museums house masterpieces like the Sistine Chapel ceiling painted by Michelangelo.\\n\\n- Rome is often referred to as the \"Eternal City\" and hosts great examples of ancient Roman architecture alongside Renaissance and modern buildings.\\n\\n- As a modern capital, it hosts the Italian government, embassies of foreign countries, and is a major transportation hub.\\n\\nLet me know if you need any other specifics about the capital city of Italy and its long, storied history.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_chain.invoke({\"input\": \"Whats the capital of Italy?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ef1e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(convo_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf614d27",
   "metadata": {},
   "source": [
    "#### `ConversationSummaryMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ccc73657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats the capital of Italy?',\n",
       " 'history': \"The human asks what the capital of India is, and the AI responds that it is New Delhi. The AI provides additional details about New Delhi, including that it is a major city located in northern India with a population over 29 million in the metropolitan area. The AI notes that New Delhi was established in 1911 by the British rulers as the new capital, replacing Calcutta (Kolkata). The city's architecture and urban planning was influenced by British architects and features grand government buildings and monuments. The AI mentions some key landmarks like India Gate, the Qutub Minar, Lotus Temple, and Red Fort. Delhi, encompassing Old Delhi and New Delhi, is considered one of the world's oldest continuously inhabited cities.\\n\\nThe human then asks what the capital of France is, and the AI states it is Paris. The AI provides details on Paris, noting it is a global center for culture, arts, fashion, gastronomy and more. It highlights famous landmarks like the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, Arc de Triomphe and Champs-Elysees. The city proper has over 2 million residents, while the metropolitan area is around 12 million, making it one of Europe's most populous urban areas. The AI mentions Paris' historical role as the seat of the French monarchy and the heart of the French Revolution, as well as its modern status as France's political and economic capital.\",\n",
       " 'response': \"The capital of Italy is Rome.\\n\\nRome is a city rich in history, culture, and iconic landmarks. As the capital, it hosts the government and many ministerial offices. Some key facts about Rome:\\n\\n- It is located in the central-western portion of the Italian peninsula, along the banks of the Tiber River.\\n\\n- With a population of around 2.8 million in the city proper and 4.3 million in the metropolitan area, it is Italy's largest city.\\n\\n- Rome was founded in 753 BCE and grew to become the capital of the powerful Roman Empire that ruled the Mediterranean world for centuries.\\n\\n- The city is home to the Vatican City, an independent city-state that is the sovereign territory of the Holy See and houses iconic sites like St. Peter's Basilica.\\n\\n- Iconic Roman landmarks include the Colosseum, Roman Forum, Pantheon, Trevi Fountain, Spanish Steps, and the Vatican Museums housing masterpieces like the Sistine Chapel frescoes.\\n\\n- Rome is considered a global city and center for art, architecture, culture, education, cuisine, fashion, finance, and tourism. It hosts many international institutions.\\n\\n- The city encompasses an incredible breadth of history from ancient Roman ruins to Renaissance and Baroque marvels across its cityscape.\\n\\nLet me know if you need any other details about the Italian capital of Rome!\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "convo_chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "convo_chain.invoke({\"input\": \"Whats the capital of India?\"})\n",
    "convo_chain.invoke({\"input\": \"Whats the capital of France?\"})\n",
    "convo_chain.invoke({\"input\": \"Whats the capital of Italy?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
