{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f259fdb-fc35-4602-8830-d88c03bc206b",
   "metadata": {},
   "source": [
    "## Creating your first LangChain project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5d0363-79fe-46a2-83c9-999a3f9cc11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800b03bb-3697-4b2f-8e80-05b895ff8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63eb7ff-eefc-4e7b-b323-ff8fddf3819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='For a great skiing destination, I would recommend cities like Aspen, Colorado; Park City, Utah; or Whistler, British Columbia.', additional_kwargs={'usage': {'prompt_tokens': 41, 'completion_tokens': 33, 'total_tokens': 74}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 41, 'completion_tokens': 33, 'total_tokens': 74}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-f7095175-e97e-4401-8a65-c916921c7c32-0', usage_metadata={'input_tokens': 41, 'output_tokens': 33, 'total_tokens': 74})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful AI that helps the user make travel plans. Respond only in a single line.\",\n",
    "    ),\n",
    "    (\"human\", \"I want to go skiing. Which city should I go to?\"),\n",
    "]\n",
    "first_msg = chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fab4f5-2ce5-4538-baea-ad5552e7196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b993656-69b2-4829-b142-8e88a9e7a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_msg.usage_metadata[\"total_tokens\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c261a-fc3a-4537-a452-62cd3a577a64",
   "metadata": {},
   "source": [
    "#### Google Generative AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835abc94-1b0f-4cf3-a90f-ecd6bea0bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35188d89-843d-482f-9af3-fa897c85a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['GOOGLE_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e341b1-4abe-441e-bfca-b65bb53324f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46fd0a-b6b2-4bbc-8418-a287375b62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful AI that helps the user make travel plans. Respond only in a single line.\",\n",
    "    ),\n",
    "    (\"human\", \"I want to go skiing. Which city should I go to?\"),\n",
    "]\n",
    "first_msg = chat.invoke(messages)\n",
    "first_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d801f-c32c-4ae0-9cc8-0d12cbe0fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1640a-aaf0-4981-9d35-8dfbf0c2a0d2",
   "metadata": {},
   "source": [
    "## Chat vs LLM in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356bddc-9f59-403e-b7ee-7733235d5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()\n",
    "city = llm.predict(\"I want to go skiing. Which city should I go to?\")\n",
    "print(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7526b-26a2-48d2-ae65-166dc6db0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "places = llm.predict(\"What else can I do in that city?\")\n",
    "print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e108e729-7d2c-41e9-9121-19be63c41649",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful AI that helps the user make travel plans. Respond only in ble line.\",\n",
    "    ),\n",
    "    (\"human\", \"I want to go skiing. Which city should I go to?\"),\n",
    "    (\"ai\", \"You should consider visiting Aspen, Colorado for a great skiing experience.\"),\n",
    "    (\"human\", \"What else can I do in that city?\"),\n",
    "]\n",
    "ai_msg = chat.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d0fad-8059-4416-ba9e-7e83c5282eb3",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216fad4-4934-4454-8291-e8f5256ff822",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537b980-86c1-4ce5-8fc4-6607674401d4",
   "metadata": {},
   "source": [
    "#### Image generation using Dall-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201c57a7-1b15-4474-b87c-158cd1496b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bce99-bbc6-462a-afd2-ee1dca3ee7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = DallEAPIWrapper().run(\"Generate a high resolution image of a cute dog\")\n",
    "image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530164c0-541f-45eb-9b6c-8cfa9671d24a",
   "metadata": {},
   "source": [
    "For other tools refer: https://python.langchain.com/v0.2/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38426503-527d-40c2-84c5-6e1c6c38b94a",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff639ff-5d49-4f26-9725-485ae7a4c0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "dictionary_template = PromptTemplate(\n",
    "    input_variables =['word'],\n",
    "    template = \"Give me a one line definition of {word}. Then, give one example of how it is used.\"\n",
    ")\n",
    "p = dictionary_template.format(word=\"Sesquipedalian\")\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb97ff-3966-460b-b0fb-ad885398e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openAILLM = ChatOpenAI()\n",
    "print(openAILLM.invoke(p).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd1a1c-84e0-4527-8535-c1aed588ffbc",
   "metadata": {},
   "source": [
    "#### Multiple input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a0c8c-d58a-46dd-b10f-a7232adb2e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "define_translate = PromptTemplate(\n",
    "    input_variables =['word','language'],\n",
    "    template = \"Give me a one line definition of {word}. Then, give the translation of that word in {language}.\"\n",
    ")\n",
    "p = define_translate.format(word=\"Sesquipedalian\", language=\"Hindi\")\n",
    "print(p)\n",
    "print(chat.invoke(p).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40c59e-db27-4b69-8a31-91d6d597d2ac",
   "metadata": {},
   "source": [
    "#### Taking input from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d8426-3d1e-4e2e-82ba-04643b9de7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog\n",
    "\n",
    "ROOT = tk.Tk()\n",
    "ROOT.withdraw()\n",
    "# the input dialog\n",
    "user_input = simpledialog.askstring(title=\"Quick Dictionary\",\n",
    "                                  prompt=\"Enter the word you want to learn about:\")\n",
    "\n",
    "dictionary_template = PromptTemplate(\n",
    "    input_variables =['word'],\n",
    "    template = \"Give me a one line definition of {word}. Then, give one example of how it is used.\"\n",
    ")\n",
    "p = dictionary_template.format(word=user_input)\n",
    "print(chat.invoke(p).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137c5c9a-d7f0-43d8-b456-c91873bb7deb",
   "metadata": {},
   "source": [
    "#### General purpose prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bb0a7-8a65-46d9-a98a-1d99f3936d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a helpful assistant.\n",
    "\n",
    "Human: {human_input}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"human_input\"], template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b3f587-7b11-4436-bd24-9298851b1edc",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c704222-f9e8-4eb8-9ee8-80f415a8a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that gives a one-line definition of the word entered by user\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(user_input=\"Sesquipedalian\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fad5a1-5717-447a-a91a-c2dcdac25c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that gives a one-line answer to user query\"),\n",
    "        (\"human\", \"Who created theory of relativity?\"),\n",
    "        (\"ai\", \"Albert Einstein developed the theory of relativity.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(user_input=\"When was it created?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77020edf-f7b5-4e64-9b74-efad2a0387e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"You are a helpful assistant that gives a one-line definition of the word entered by user\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(input=\"Callous\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529789e-0ec6-425c-aeee-4d796c577575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5356815-6ead-463a-8278-0c62a153d692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50cd01b-8fa0-4087-b681-a4cb18c7532f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a63b6db6-ee59-4bdf-b583-6e397dfa1c2a",
   "metadata": {},
   "source": [
    "#### Few shot prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af4873-4ee5-4cff-b94c-0000bb397d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"rev\": \"I love this product\",\n",
    "        \"answer\": \"positive\"\n",
    "    }, {\n",
    "        \"rev\": \"It was an average experience\",\n",
    "        \"answer\": \"neutral\"\n",
    "    },{\n",
    "        \"rev\": \"I wonder why it is so highly rated.\",\n",
    "        \"answer\": \"negative\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"rev\", \"answer\"],\n",
    "    template= \"\"\"\n",
    "User: {rev}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"Identify the sentiment of the user review. Here are some examples: \"\n",
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {review}\n",
    "AI: \"\"\"\n",
    "\n",
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"review\"],\n",
    "    example_separator=\"\\n\"\n",
    ")\n",
    "\n",
    "user_review = \"Well structured. Five stars.\"\n",
    "\n",
    "print(few_shot_prompt_template.format(review=user_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e52f7-6df3-445f-892e-936ba043c054",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a2ebb-4d6e-461f-addc-1f91d4a9c90a",
   "metadata": {},
   "source": [
    "#### Generic chain - LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3ea2f-eca0-4e5c-b3b8-21d895f935de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dictionary_template = PromptTemplate(\n",
    "    input_variables =[\"word\"],\n",
    "    template = \"Give me a one line definition of {word}. Then, give one example of how it is used.\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "#p = dictionary_template.format(word=\"Sesquipedalian\")\n",
    "#print(chat.invoke(p).content)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=dictionary_template)\n",
    "chain.invoke(\"Anachronism\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d60b82-8b46-42bd-b509-a68cdec0a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = [\n",
    "    {\"word\": \"Sesquipedalian\"},\n",
    "    {\"word\": \"Anachronism\"},\n",
    "    {\"word\": \"Onomatopoeia\"}\n",
    "]\n",
    "\n",
    "chain.apply(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e9e6a-97f5-4334-a911-f188ef463d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.generate(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf5c3d-4f33-410d-ae72-0f17b05ad5da",
   "metadata": {},
   "source": [
    "#### Utility chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3319f9-afa7-475c-a133-a069a3bb1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91a149-671e-45de-80a2-4ab1c944809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new code\n",
    "calculator = LLMMathChain.from_llm(llm, verbose=True)\n",
    "calculator.invoke(\"Calculate (625 raised to power (0.225))-(log10(100))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac403e-1b85-49d7-972b-1a47e0f832b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculator.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c67ef-024e-4be6-bc2f-b77a15894f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_llm =ChatOpenAI()\n",
    "messages = [\n",
    "    (\"human\", \"Calculate (625 raised to power (0.225))-(log10(100))\"),\n",
    "]\n",
    "calculation = calc_llm.invoke(messages)\n",
    "print(calculation.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cd929-e0f3-433d-944d-6edf359ae95f",
   "metadata": {},
   "source": [
    "##### List of all chains - https://python.langchain.com/v0.1/docs/modules/chains/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babbbe02-985d-41a1-93d3-8455290fc52f",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ca167-0fd8-4b5b-bd92-3121a57a7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_text = PromptTemplate(\n",
    "    input_variables =['name','description'],\n",
    "    template = \"Generate a one line facebook ad copy for a product called {name}. Below is a description of this product: {description}\"\n",
    ")\n",
    "\n",
    "text_llm = ChatOpenAI()\n",
    "\n",
    "text_chain = LLMChain(llm=text_llm, prompt=marketing_text, output_key=\"copy_text\")\n",
    "\n",
    "\n",
    "translate_text = PromptTemplate(input_variables=[\"copy_text\"], template=\"\"\"Translate this text to Hindi:\n",
    "\n",
    "{copy_text} \"\"\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "translate_llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "translate_chain = LLMChain(llm=translate_llm, prompt=translate_text, output_key=\"translated_copy\")\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "seq_chain = SequentialChain(\n",
    "    chains = [text_chain, translate_chain],\n",
    "    input_variables = [\"name\", \"description\"],\n",
    "    output_variables = [\"copy_text\",\"translated_copy\"]\n",
    ")\n",
    "\n",
    "seq_chain({\"name\": \"AeroGlow Nightlight\",\"description\":\"AeroGlow Nightlight is a smart, voice-activated nightlight that projects calming, animated constellations onto your ceiling.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c840445-71ee-41cb-b66a-315afc9f2bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43624fd3-79b3-4eaf-adfb-eeb3d025c982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796a5aa-881f-48bd-986d-ff0dc8c022ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1c7c0c-11c1-4228-8baf-f945b5ad6114",
   "metadata": {},
   "source": [
    "### LCEL - Pipe operator and Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774788d-7e27-4beb-aab4-52c4ede460c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "dictionary_template = PromptTemplate(\n",
    "    input_variables =[\"word\"],\n",
    "    template = \"Give me a one line definition of {word}. Response should not contain the word - {word} itself, only the meaning.\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = dictionary_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a4000-dec2-469d-a25d-2f387cc61d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"word\": \"Onomatopoeia\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62862c-bdea-4b43-8eb8-25546ea06f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "guesser_template = PromptTemplate(\n",
    "    input_variables =[\"definition\"],\n",
    "    template = \"Give me an English word which has the following meaning- {definition}.\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain2 = guesser_template.pipe(llm).pipe(StrOutputParser())\n",
    "chain2.invoke(\"A word that imitates the sound it represents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d51d2e3-c821-4763-905b-1f60c8013d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_chain = {\"definition\": chain} | chain2\n",
    "\n",
    "seq_chain.invoke({\"word\": \"Sesquipedalian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f099cc2a-06f4-4a5f-8681-19f7eebb483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275032b3-ef08-46a8-948f-4e6a80619508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "834f54d8-949f-411d-abb3-99c6df7da72c",
   "metadata": {},
   "source": [
    "#### RunnablePassthrough, RunnableLambda and RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282749e-b662-4839-870a-42c6f1d6868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077af250-ef29-4283-b052-319978c7137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730e308-d044-4e22-8153-461607f493d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"abcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c670c3-f9ae-4b85-a27e-46973f324131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_length(input: str):\n",
    "    output = len(input)\n",
    "    return output\n",
    "\n",
    "chain = RunnableLambda(output_length)\n",
    "chain.invoke(\"input to output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534e815-97df-4655-856e-cb178833cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(text = RunnablePassthrough(), length = RunnableLambda(output_length))\n",
    "chain.invoke(\"start-tech academy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed84747-1eff-48a5-892d-bef72913c3e3",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08baa41b-8390-44b9-888b-67369ad91f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "explainer_template = PromptTemplate(\n",
    "    input_variables =[\"topic\"],\n",
    "    template = \"Explain this topic in a single paragraph as if you were explaining it to a 10 year old - {topic}.\"\n",
    ")\n",
    "\n",
    "openAIllm = ChatOpenAI()\n",
    "\n",
    "OpenAI_chain = explainer_template | openAIllm | StrOutputParser()\n",
    "OpenAI_chain.invoke({\"topic\": \"Gravity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad5205-48bb-4219-bd8d-f852e160ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "googlellm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "google_chain = explainer_template | googlellm | StrOutputParser()\n",
    "google_chain.invoke({\"topic\": \"Gravity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb4e88-6fa9-44ea-bd79-9f2049b6168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_template = PromptTemplate(\n",
    "    input_variables =[\"topic\", \"explanation1\", \"explanation2\"],\n",
    "    template = \"\"\"\n",
    "    Which of the two explanations given below are better for explaining {topic} to 10 year old students.\n",
    "    ###\n",
    "    Explanation 1 - {explanation1}\n",
    "    ###\n",
    "    ***\n",
    "    Explanation 2 - {explanation2}\n",
    "    ***\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "combined_chain = (\n",
    "    RunnableParallel({\"explanation1\": OpenAI_chain, \"explanation2\": google_chain, \"topic\": RunnablePassthrough()})\n",
    "    | analyzer_template | openAIllm | StrOutputParser()\n",
    ")\n",
    "\n",
    "combined_chain.invoke({\"topic\": \"Gravity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60fc944-e82b-423e-9e17-effc5b0eb805",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_chain = analyzer_template | googlellm | StrOutputParser()\n",
    "\n",
    "updated_chain = (\n",
    "    RunnableParallel({\"explanation1\": OpenAI_chain, \"explanation2\": google_chain, \"topic\": RunnablePassthrough()}) \n",
    "    | RunnableParallel({\"input\": RunnablePassthrough(), \"analysis\": analyzer_chain})\n",
    ")\n",
    "\n",
    "updated_chain.invoke({\"topic\": \"Gravity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ad1e7-25dd-4998-8a56-b42c1dfe9ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72714923-2c40-4e3c-a6cf-26b041bbc87c",
   "metadata": {},
   "source": [
    "#### Dynamic Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af030eef-b44c-4b0b-94d1-a1d230c06d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "classifier_template = PromptTemplate(\n",
    "    input_variables = [\"question\", \"answer\"],\n",
    "    template = \"\"\"You are given a question and the user's response to that question. Classify the response as either `Correct`, or `Incorrect`.\n",
    "    Do not respond with more than one word.\n",
    "    Question - {question}\n",
    "    User's Answer - {answer}\n",
    "    Classification:\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "classifier_chain = classifier_template | llm | output_parser\n",
    "\n",
    "classifier_chain.invoke({\"question\": \"what are penguins\", \"answer\": \"Penguins are birds\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467361d7-5673-4f43-9cd2-9147b9d5579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_template = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "    template = \"\"\"The user was asked the following question and user answered it correctly. Now ask a more difficult question on the same topic to the user.\n",
    "    Question: {question}\n",
    "    New Question:\"\"\"\n",
    ")\n",
    "\n",
    "correct_chain = correct_template | llm | output_parser\n",
    "\n",
    "incorrect_template = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "    template = \"\"\"The user was asked the following question and user answered it incorrectly. Give the correct answer and explain it to the user.\n",
    "    Question: {question}\n",
    "    Correct Answer:\n",
    "    Explanation: \"\"\"\n",
    ")\n",
    "\n",
    "incorrect_chain = incorrect_template | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63282c-7a0a-4c60-9e34-a4c1dc1b89d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    if  info[\"result\"].lower() == \"correct\":\n",
    "        return correct_chain\n",
    "    elif info[\"result\"].lower() == \"incorrect\":\n",
    "        return incorrect_chain\n",
    "    else:\n",
    "        return \"Format is not correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5d019-2571-4e8d-93a2-3d8f5d501f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "\n",
    "final_chain = RunnableParallel({\"result\": classifier_chain, \"question\": lambda x: x[\"question\"], \"answer\": lambda x: x[\"answer\"]}) | RunnableParallel({\"response\":RunnableLambda(route), \"input\": RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b70b4a-b4d5-418b-99c7-90414a7a330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke({\"question\": \"what are penguins\", \"answer\": \"Penguins are sea animals\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc633ba1-b032-4767-ba27-b00c4a9faea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke({\"question\": \"what are SQL joins\", \"answer\": \"Joins are used to join two queries\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cba98-fdf0-492a-a304-42736f502942",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke({\"question\": \"what are SQL joins\", \"answer\": \"SQL joins are operations used to combine rows from two or more tables based on a related column\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7260e1-7da9-401d-951d-5a11d61e2ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1233742-ce0a-4db3-8e86-49d93eb9d993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec9c892f-4c38-4c07-9569-ba2d9ded87bc",
   "metadata": {},
   "source": [
    "### Output Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2dde5-464b-4898-8050-59279ae8db2b",
   "metadata": {},
   "source": [
    "#### StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa4a38-8ed3-41f8-b8d0-3f879a3fb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "dictionary_template = PromptTemplate(\n",
    "    input_variables =[\"word\"],\n",
    "    template = \"Give me a one line definition of {word}. Response should not contain the word itself, only the meaning.\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = dictionary_template | llm \n",
    "chain.invoke(\"Onomatopoeia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbf31e-0f3e-491b-ba40-17dc68aca59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "dictionary_template = PromptTemplate(\n",
    "    input_variables =[\"word\"],\n",
    "    template = \"Give me a one line definition of {word}. Response should not contain the word itself, only the meaning.\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = dictionary_template | llm | StrOutputParser()\n",
    "chain.invoke(\"Onomatopoeia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bc048-a929-4e4a-965c-ac75649642c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79238ed6-ebea-49d9-814c-deac159b9d54",
   "metadata": {},
   "source": [
    "#### StructuredOutputParser - Output as a specified Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2741b-06b0-43ac-a6a1-7e5cca4321a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"word\", description=\"word entered by user\"),\n",
    "    ResponseSchema(name=\"meaning\", description=\"One line meaning of the word given by user\"),\n",
    "    ResponseSchema(name=\"example\", description=\"An example of how that word can be used in a line\"),\n",
    "    ResponseSchema(name=\"Etymology\", description=\"Origin or history of the word\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772dff5-5214-4207-b67c-559127db6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Provide the meaning, an example of how the word is used in a sentence and the etymology of this word: {word}.\\n{format_instructions}\",\n",
    "    input_variables=[\"word\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "chain = prompt | chat_model | output_parser\n",
    "\n",
    "chain.invoke(\"Onomatopoeia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2f9ff-fe1b-4b8f-8fe0-7ba0c56faaf1",
   "metadata": {},
   "source": [
    "#### Comma separated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72eb93a-d1ed-4618-ae12-88cf6251b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {topic}.\\n{format_instructions}\",\n",
    "    input_variables=[\"topic\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model | output_parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063d746-7641-422e-a856-d7417de57163",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf63d35-ba2a-471d-bdf8-c6c83e90d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"healthy foods\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1f4ec-2845-4381-89ec-ec057b4ecb11",
   "metadata": {},
   "source": [
    "#### Date Time Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9aafee-1bce-4421-b045-635894068fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "output_parser = DatetimeOutputParser()\n",
    "template = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "prompt = PromptTemplate.from_template(\n",
    "    template,\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858cd32-a910-4f15-b897-e9b1e66a4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3fb394-79c8-47a6-92a2-c6fc7183a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f979512-e2ce-461f-8934-4e31f0dd052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"question\": \"When did India get independence?\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501c674-1e83-40f4-a0ab-e4aa48eafa59",
   "metadata": {},
   "source": [
    "Output Parser Documentation - https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/quick_start/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac70e2-315c-4239-bca3-3116c1da9a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c566c-04b9-4184-bacd-3049f27bc424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92c28ecf-a3b2-44f7-a149-dabb71c6b4d0",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f203d72-fdde-43c4-92c3-68c70353e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables =[\"history\", \"new_input\"],\n",
    "    template = \"\"\"You are having a chat with a human.\n",
    "    previous chat: {history}\n",
    "    Human: {new_input}\n",
    "    Assistant: \"\"\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "#llm = ChatOpenAI()\n",
    "llm = OpenAI()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory = memory, verbose=True)\n",
    "\n",
    "chain.invoke({\"new_input\": \"Which country is the biggest exporter of cotton?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151cef3-e19b-43f5-80ed-5c6faf0ff76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"new_input\": \"What is the total value of cotton exports of this country\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa6dda-92e3-40ee-a063-7d875b4c7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are having a chat with a human.\"\n",
    "        ), \n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"history\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{new_input}\"\n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "chat_llm = ChatOpenAI()\n",
    "\n",
    "chat_chain = LLMChain(llm=chat_llm, prompt=chat_prompt, memory = chat_memory, verbose=True)\n",
    "\n",
    "chat_chain.invoke({\"new_input\": \"Which country is the biggest exporter of cotton?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3a653-8ad4-4335-ac19-89dfeb707fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain.invoke({\"new_input\": \"What is the total value of cotton exports of this country\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec49148-a412-415d-949f-d9d29c43f935",
   "metadata": {},
   "source": [
    "#### Changing the memory variable name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede194f-5de6-4a3e-a3c7-84f5df9daf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are having a chat with a human.\"\n",
    "        ), \n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"prev_conv\"\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{new_input}\"\n",
    "        ),  \n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_memory = ConversationBufferMemory(memory_key=\"prev_conv\", return_messages=True)\n",
    "\n",
    "chat_llm = ChatOpenAI()\n",
    "\n",
    "chat_chain = LLMChain(llm=chat_llm, prompt=chat_prompt, memory = chat_memory, verbose=True)\n",
    "\n",
    "chat_chain.invoke({\"new_input\": \"Which country is the biggest exporter of cotton?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d6afd-761b-416e-9bb1-800c6eeb58f1",
   "metadata": {},
   "source": [
    "#### Adding messages to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26466d19-6293-45df-8fa6-776afad26f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_memory = ConversationBufferMemory(memory_key=\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df409b3-14b1-455c-8357-8902fcb18ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78ec3f-b168-420f-b281-5edb5127e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_memory.chat_memory.add_user_message(\"Which country is the biggest exporter of cotton?\")\n",
    "sample_memory.chat_memory.add_ai_message(\"China\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69ebc7-844e-48b2-9dad-6383eaf6bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010ea01-208d-4af2-b1ae-172e3174b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables =[\"history\", \"new_input\"],\n",
    "    template = \"\"\"You are having a chat with a human.\n",
    "    previous chat: {history}\n",
    "    Human: {new_input}\n",
    "    Assistant: \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template, memory = sample_memory, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87751b1e-61fa-4cf4-9ff2-4d64442894a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"new_input\": \"What is the total value of cotton exports of this country\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37b9b1-300a-4a5c-a661-1dec203924d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e5d576e-df6e-4cac-9fc1-6e82f12dfe5f",
   "metadata": {},
   "source": [
    "#### Conversation Chain instead of LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791f8a8-dbf7-4e04-85ec-5eb94a3aeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"history\")\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chain = ConversationChain(llm=llm, memory = memory, verbose=True)\n",
    "\n",
    "chain.invoke({\"input\": \"Which country is the biggest exporter of cotton?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af340435-a566-4428-a74e-fbbcca2e585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823c8cf-0ccd-4a2d-bbcf-a09e5ae5a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"What is the total value of cotton exports of this country\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387d17e-8159-4498-95c9-b8fda237243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65188bef-e80a-4c10-9e6d-04fae568a81a",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea39c3-94b4-4bc3-900d-ed3e49636001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "convo_chain = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "convo_chain.invoke({\"input\": \"Which country is the biggest exporter of cotton?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc40154-9493-4635-afde-3cee30566f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_chain.invoke({\"input\": \"What is the total value of cotton exports of this country\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a3293-24ee-408e-9e16-f0214baa0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(convo_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5de08-8c36-4ee2-8631-efa5b8b3d27c",
   "metadata": {},
   "source": [
    "#### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f77e29-82ab-42f4-a74a-a3fbd0057ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\n",
    "memory.save_context({\"input\": \"Which country is the biggest exporter of cotton?\"}, {\"output\": \"China\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607259e-7f7c-4aa3-a771-44800c5a63d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed07b39-e281-4131-a00a-355ea8a5ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.invoke(input=\"Which country is the biggest exporter of cotton?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5900ffd-5d0e-4d0e-8a1c-3e2dc813f6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_with_summary.invoke(input=\"What is the total value of cotton exports of this country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394510ef-a5cd-498e-aec8-811c611e0c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d61a4c8-e59e-4212-ad20-6ea85d91bda6",
   "metadata": {},
   "source": [
    "#### Runnable with Message History with session ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f77b1e-71e9-418f-a64d-0523d836f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are having a chat with a human.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f02184-1108-47e6-b6e1-3c6c214292d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "runnable = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d24592-3a4f-40cf-8c5e-ffbee71bb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke(\n",
    "    {\"input\": \"Which country is the biggest exporter of cotton?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"sess1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22ffd9-7623-45ea-b01e-635b1ceaee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remembers\n",
    "runnable.invoke(\n",
    "    {\"input\": \"What is the total value of cotton exports of this country\"},\n",
    "    config={\"configurable\": {\"session_id\": \"sess1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ab392-329b-436a-bfa0-60adb1515c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New session_id --> does not remember.\n",
    "runnable.invoke(\n",
    "    {\"input\": \"What is the total value of cotton exports of this country\"},\n",
    "    config={\"configurable\": {\"session_id\": \"sess2\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d425e-3d15-412d-be11-35d880ab7f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbc2ab-eac1-413b-803d-dd330749308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bf67b-ace6-4a4b-884b-39657de61f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f77efd-ed23-4c6a-8b01-817688dfde26",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5503a6-6fa9-4678-b62b-c30beababac6",
   "metadata": {},
   "source": [
    "### Document Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d33507-18a4-4ee5-8621-5c5bcdd5ae09",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb6f80-367e-4653-a2e3-d7cbdabd7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./RAGfiles/LangchainRetrieval.txt\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e881d22-d458-4d11-bb63-cce488a264d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c237d2-7fe2-43ce-88c9-0ca47a7c608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a672f3-62c6-496b-ba6b-4f3848f3ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./RAGfiles/Excel Course Document.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33235a3e-a04c-4d20-8dff-9a227d8bbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9e530-57cd-4903-a47e-f40dee21381a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f02ce-c6d4-4981-858b-94de631ce35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader('./RAGfiles/', glob=\"**/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ba415-4bc9-4bbe-8f4a-2e4aeda27dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9fe1e-f1b9-4989-93ca-66796c41cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1abf6-b585-4f0d-8b16-ec0f311479a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a4fdd-2437-4cee-892e-89fb48508664",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./RAGfiles/', glob=\"**/*.txt\", show_progress=True)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6603f-c687-43d7-b64f-0cf82236a535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc160fd-901d-43bf-be89-535c9c6b2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "\n",
    "loader = CSVLoader(file_path='./RAGfiles/Movie_collection_dataset.csv')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964539f7-682d-471d-bd9e-5273e2cc60bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a6ac4-92cb-4bd4-bd6c-9ea6d24c6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path='./RAGfiles/Movie_collection_dataset.csv', csv_args={\n",
    "    'delimiter': ',',\n",
    "    'quotechar': '\"',\n",
    "    'fieldnames': ['Genre', 'Budget', 'Actor_rating']\n",
    "})\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46541a8-3002-4bb8-83b5-da65ff083687",
   "metadata": {},
   "source": [
    "### Splitting the document - Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603cc40-f593-4c2a-ac12-7a0629e9a8ab",
   "metadata": {},
   "source": [
    "#### Recursively split by character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b9674-97ed-491d-96c4-35e0712be9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c7989-94b4-421a-a38b-902446e6c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./RAGfiles/LangchainRetrieval.txt\")\n",
    "text = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519ac67-afb8-4cd0-b3e3-a22887477a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183aab0-5887-4cc3-9e18-9728d7d26eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd479e-1304-4ac3-97d9-e500f8bd1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf36ebb-26fd-44e8-a528-236dc18a05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(text)\n",
    "print(texts[0])\n",
    "print(texts[1])\n",
    "print(texts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ccf131-6d65-4234-9061-0f64b4f08edf",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba02952-93a4-440b-bcda-74bb6de75e8e",
   "metadata": {},
   "source": [
    "#### OpenAI embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af19587-8a3b-4562-9987-8e9b4fd653c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422fdd0-d2c0-414f-845d-71f52cebea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa9e78-c9c8-4f45-9b75-54afe4dbc771",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"Hi\",\n",
    "        \"What's up!\",\n",
    "        \"Learning LangChain\",\n",
    "        \"You should learn it from Start-Tech Academy\"\n",
    "    ]\n",
    ")\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9218715-2d32-4984-ac40-c3d30e055adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b801d-4385-45d0-813b-abfde0d7727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "embedded_query[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b96fde-9abb-4e14-addb-adbfd982e9a3",
   "metadata": {},
   "source": [
    "#### Huggingface embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda4d7e-b5d5-4735-9343-f2a9bf49f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6cfe72-ace9-466c-9f78-255fa810284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "embeddings_model = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade6737-564e-4ff2-bd6e-2b9f16ce9485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cba206c-313f-425e-bc04-5fb7df96c5bf",
   "metadata": {},
   "source": [
    "### Vector Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d900d5-867f-4c3f-b0ba-bb680f4e5fac",
   "metadata": {},
   "source": [
    "#### Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5881838-286c-4461-90b7-b4b3d3443d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d6eaf-0e3f-40c2-b78a-43a83125c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader(\"./RAGfiles/LangchainRetrieval.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152786e-4f03-40e0-8592-5ac3b16bf6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is text embedding and how does langchain help in doing it\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd9ac0-a7a7-4554-a1d8-c10423f0f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector = OpenAIEmbeddings().embed_query(query)\n",
    "docs = db.similarity_search_by_vector(embedding_vector)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb84a4b-3fd6-42c5-a4b8-955fcbe78502",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a0467-9169-47ad-b184-6242401d0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader(\"./RAGfiles/LangchainRetrieval.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e47403-5ac0-487c-ba21-2ed9c2a0932d",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379a0f56-3895-439d-96e2-9a686cf859b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader(\"./RAGfiles/LangchainRetrieval.txt\").load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232769a8-8bc7-4032-b130-824b26b6daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b1aeb-d13c-4036-82bc-77ba310a7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is text embedding and how does langchain help in doing it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49eeb7-ee6d-47ae-87f7-bf10cab3e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902243c5-0ba7-4e0c-9d16-fcfe8eb9a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"What is text embedding and how does langchain help in doing it\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a7beb-1e56-488d-9dc1-a1b417495a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6724a-d0b5-4355-8fa1-048d998d62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is text embedding and how does langchain help in doing it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520309dd-5f14-44f5-a4cb-011c9cce38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94324a9-0c46-4b7d-b51d-e47c3e23e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6900c24-38a2-427e-977a-9ebfd76e586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"What is text embedding and how does langchain help in doing it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d1e57-a0f2-4a48-8d06-a7cc337c6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a11410-6b6a-4ffb-ad25-fac51e583ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c4243-8286-4e41-888f-776f8c20002a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26d0e4-376e-4546-9363-17c43ce23ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1c8519-7dce-4afd-bd9b-12c821000cca",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407a6219-3f8c-45ad-afaa-4e61011649fc",
   "metadata": {},
   "source": [
    "#### Creating own custom tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece05c41-4f2f-4057-8a1e-e955171ded81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0b5c1-cbcd-49ef-a565-3ae62bd9d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def name_of_tool(input: str) -> str:\n",
    "    \"\"\"Tool_Description\"\"\"\n",
    "    return \"Result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68706218-3b55-4bbb-938e-b8b86bd622e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_of_tool.name)\n",
    "print(name_of_tool.description)\n",
    "print(name_of_tool.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c79a7-36ed-4497-8927-d7106e431b46",
   "metadata": {},
   "source": [
    "#### Defining, Binding and Calling the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2512f-df26-4b84-8497-0ecce269e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sta_coins(input: float) -> float:\n",
    "    \"\"\"Use this tool to convert USD to Start-Tech Academy coins\"\"\"\n",
    "    return 1.3*(float(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7437a0-f69b-4235-879a-801450993478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm_bind_tools = llm.bind_tools([sta_coins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffcabeb-30dd-4a80-be9d-ea96cbd92be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_bind_tools.invoke(\"How many start-tech academy coins can I get for USD10\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95b81f-e132-4029-8179-fe4c78e9e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a7e29-941b-4dfe-b8c7-5acf55af8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_mapping = {\n",
    "    'sta_coins': sta_coins\n",
    "}\n",
    "tool_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7771c66-f5df-491e-b38f-54425763b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = tool_mapping[result.tool_calls[0][\"name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c7a9b-5827-44a8-9998-a5bf23c93920",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_output = tool.invoke(result.tool_calls[0][\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c7957-43b5-4918-862f-63832880ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f1568-c6a2-4c2d-94c9-6d72455e0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiple tool calls in LLM response, we can loop through the list of tools in tool call\n",
    "tool_mapping = {\n",
    "    'sta_coins': sta_coins\n",
    "    'tool2_name': tool2\n",
    "}\n",
    "tool_mapping\n",
    "for tool_call in result.tool_calls:\n",
    "    tool = tool_mapping[tool_call[\"name\"]]\n",
    "    tool_output = tool.invoke(tool_call[\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8715212-668f-4c62-ab67-1bd4cceb4d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733a4a33-6009-42a5-884a-8c40cc4bbec6",
   "metadata": {},
   "source": [
    "### Using in-built tools\n",
    "https://python.langchain.com/v0.1/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe486a-bd6e-42a4-a708-bf3fd4db9234",
   "metadata": {},
   "source": [
    "#### DuckDuckGo Search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617bd79-6d6d-4276-8b13-817bdff43ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fd7a1-1a25-44a6-ae7e-a72836e8d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9cb32-c707-4554-8155-c3fa47b74c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.name, search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3aeae-449a-443e-b0ae-ca2aa7a82ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.run(\"What are tools in Langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c77f2a-a265-42c5-bd59-60f71625702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "search = DuckDuckGoSearchResults()\n",
    "search.invoke(\"What are tools in Langchain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23166e3a-a759-47b3-bd15-2fe2263d5be8",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3337f-d808-41bc-97fc-95b5c00ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4916b-61a0-4891-803d-7fae8df66ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "wikipedia.invoke(\"LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6dccee-9e6f-419f-8e7e-3a97b070ab81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2484867-0125-41f6-9bdd-7e4f1fc091fc",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5288d-4e30-49b2-a03f-d2f1a30b9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. For answering the user query, look for information using DuckDuckGo Search and Wikipedia and then give the final answer\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [search, wikipedia]\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0454053-af6d-41e1-897f-f29d3bf0eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62729bf-d952-4d27-8a51-aba553bb7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d8bc3-a120-4177-a55e-4c96782d1419",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"weather in delhi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d3002-b8c0-457d-bd3e-b317f056e0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_executor.invoke({\"input\": \"When was Nelson Mandela born and what are some of his famous quotes?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822f516-8ac4-4914-b4e0-3f183fce70da",
   "metadata": {},
   "source": [
    "#### Agent with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac5123-fe16-413b-bb6c-82e725ec9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Based on user query and the chat history, look for information using DuckDuckGo Search and Wikipedia and then give the final answer\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca935f8-4296-463f-8cad-6093758026a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "agent_with_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89395ffd-7615-4d84-8db3-f28542e80b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent_with_history.invoke(\n",
    "    {\"input\": \"When was Nelson Mandela born?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"sess1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105357d-3c2e-4cf2-a452-f66b4dc645f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = agent_with_history.invoke(\n",
    "    {\"input\": \"What are some of his famous quotes?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"sess1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176caad-5efe-4f9d-a5f0-9edfb52ada3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c08d38-c078-428d-8298-b92a5dffc59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e92396-8c13-4262-a1f1-2fa892f43d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a460774-0510-498a-b89c-c34871d658be",
   "metadata": {},
   "source": [
    "### LangSmith for monitoring the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b9c07-e0fd-401c-8d3f-9b9663d3040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"langchain_course\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c5fb8-3f14-4f2e-b6d8-ca8385cee413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09519f0b-f03f-4245-acd9-73cf5fcbe5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "tools = [search, wikipedia]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Based on user query and the chat history, look for information using DuckDuckGo Search and Wikipedia and then give the final answer\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "agent_with_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "agent_with_history.invoke(\n",
    "    {\"input\": \"When was Nelson Mandela born?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"sess1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3df601-57fb-4e21-acc7-ca01a3cc4aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9194566-1fb5-4bbe-8f84-2aca8441d687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408943d8-b846-45d4-877c-883491a78a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e932de6-bf16-4693-9691-05234a4843d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1dbcf3-c68c-4215-896b-1cbe3cef9fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faf698-071b-48f1-af61-1aa54256baf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cc8fe-cb4b-44cd-88ec-7eaa53617c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
