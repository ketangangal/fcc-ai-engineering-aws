nan | based neural machine translation. arXiv preprint arXiv:1508.04025, 2015.
[22] | Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention
nan | model. In Empirical Methods in Natural Language Processing, 2016.
[23] | Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive
nan | summarization. arXiv preprint arXiv:1705.04304, 2017.
[24] | Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv
nan | preprint arXiv:1608.05859, 2016.
[25] | Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words
nan | with subword units. arXiv preprint arXiv:1508.07909, 2015.
[26] | Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,
nan | and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts
nan | layer. arXiv preprint arXiv:1701.06538, 2017.
[27] | Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-
nan | nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine
nan | Learning Research, 15(1):1929–1958, 2014.
[28] | Sainbayar Sukhbaatar, arthur szlam, Jason Weston, and Rob Fergus. End-to-end memory
nan | networks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,
nan | Advances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,
nan | Inc., 2015.
[29] | Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural
nan | networks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.
[30] | Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.
nan | Rethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.
[31] | Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang
nan | Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine
nan | translation system: Bridging the gap between human and machine translation. arXiv preprint
nan | arXiv:1609.08144, 2016.
[32] | Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with